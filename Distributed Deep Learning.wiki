= Distributed Deep Learning =

== Categories ==

=== Model Parallelism ===
 * Train very large models
 * Speed up model training
 * Can only parallelize to the extent the model allows

=== Data Parallelism ===
 * More Generally appicable
 * Addtionaly Complexity of State Synchronization

==== Data Parallelism Techniques ====



